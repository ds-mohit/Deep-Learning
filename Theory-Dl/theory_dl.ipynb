{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4519fe",
   "metadata": {},
   "source": [
    "# ```Deep Learning```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0cc6b5",
   "metadata": {},
   "source": [
    "#### ```it behave like human ```\n",
    "```and it is used in solving complex problems where machine learning fails (show drawbacks)```\n",
    "```it is used to handle data that is in the form of 3-d and more like text recoginition,image ,etc.```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb424d",
   "metadata": {},
   "source": [
    "#### ```Dl algo are :```\n",
    "```1.  Ann(Artifical neural network) mimic like  human brain. :: ```  in this we deal with linear and logistic regression\n",
    "\n",
    "```2. Cnn(Convolutional neural network) mimic like eye . :: ```  in this we deal with images and image processing\n",
    "\n",
    "```3. Rnn(Recurrent neural network) mimic like speech . :: ```  in this we deal with nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8bebd",
   "metadata": {},
   "source": [
    "```for more info visit below link```\n",
    "(use this link)[https://chatgpt.com/share/686df07f-a3cc-800b-b286-8e3f0a9390aa]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a738f18",
   "metadata": {},
   "source": [
    "#### Deep Learning uses GPU whereas Machine Learning uses CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40290a17",
   "metadata": {},
   "source": [
    "# ANN (Artifical neural network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0d3de",
   "metadata": {},
   "source": [
    "it is based on human brain\n",
    "## Diagram of ANN\n",
    "<img src= \"NeuralDiagram.webp\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b6e9c4",
   "metadata": {},
   "source": [
    "## Diagram of MNN\n",
    "<img src =\"MnnDiagram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471c87f",
   "metadata": {},
   "source": [
    "in ```ann``` the ```input nodes``` are based on the ```no of features``` and it use x data which are independent \n",
    "\n",
    "and ```no of  hidden layer and nodes``` is depend on ```human itself``` ```or model training ker isaab se```\n",
    "\n",
    "and ```output ```is depend on ```regression ``` (output is single) and ```classification -->```  ```binary classification``` ( classify data in only two class like win loss) \n",
    "\n",
    "and ```multiclass classification``` (classify data on more then two class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d22c06",
   "metadata": {},
   "source": [
    "### ```Percepton``` \n",
    "it is the smallest unit of neural network\n",
    "\n",
    "for more info\n",
    "(click on it )[https://chatgpt.com/share/686dfad2-1af8-800b-bd2c-50e8b98cfd68]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d4413",
   "metadata": {},
   "source": [
    "<img src=\"Perceptron.png\">\n",
    "\n",
    "here weights are trainable parameters and initially they are assigned as randomly \n",
    "\n",
    "and later on training of the machine they reach to their optimal value\n",
    "\n",
    "```### Weighted sum```\n",
    "\n",
    "here z is weighted sum of inputs z= w1*x1+w2*x2+bias\n",
    "\n",
    "bias is used to avoid overfitting and it is added to the weighted sum and it is constant value\n",
    "\n",
    "\n",
    "```#### Activation Function```\n",
    "\n",
    "it is used to add non linearity to the network whereas non linearity is defined as Real-world data is often and  non-linear means moving data in the range. \n",
    "\n",
    "Activation functions help the neural network learn and model this non-linearity.\n",
    "\n",
    "for example in step wise function if value of z > 0 then 1 else 0\n",
    "\n",
    "```#### Types of Activation Function```\n",
    "\n",
    "```1. Step function :``` it is applied on output layer and it's range is from 0 to 1\n",
    "\n",
    "```2. Sigmoid function :``` is used on output layer during binary classification it give probability based output (0,1)\n",
    "\n",
    "```3. Tanh function :``` it is applied on hidden layer and it's range is from -1 to 1 and it is not used nowdays \n",
    "\n",
    "```4. ReLu function :``` it is applied on hidden layer and it's range is from -1 to 1 and it is most used \n",
    "\n",
    "```4.1. Parametric ReLU function :``` it is applied on hidden layer and it's range is from -1 to 1 it uses hyperparameter(value can be added acc to user) to solve dead node .\n",
    "\n",
    "```4.2. leaky ReLU function :``` it is applied on hidden layer and it's range is from -1 to 1 (it uses multiplication to remove dead node)\n",
    "\n",
    "```4.3. Exponential Relu function :``` it uses exponential value to solve dead node problem. it is applied on hidden layer.\n",
    "\n",
    "```5. linear function :``` it is used on output layer during regression\n",
    "\n",
    "```6. softmax function :``` it is used on output layer during multi class classification it give probability based output (0,1)\n",
    "\n",
    "(link for more info)[https://chatgpt.com/share/686dff6a-98a4-800b-b707-0c647e1288d2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb92347",
   "metadata": {},
   "source": [
    "### Forward Propagation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f36ddb3",
   "metadata": {},
   "source": [
    "Forward Propagation is the first phase in training a neural network where the input data passes through the network, layer by layer, to produce an output (prediction).\n",
    "\n",
    "for more info [https://chatgpt.com/share/686e0004-5188-800b-a809-336ff879936f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f888cd",
   "metadata": {},
   "source": [
    "### Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597cfcc",
   "metadata": {},
   "source": [
    "it is the second phase in training a neural network where the error is backpropagated through the network, layer by layer, to adjust the weights and biases of the network.\n",
    "\n",
    "for more info [https://chatgpt.com/share/686e005e-1470-800b-a795-8a394e02883f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a3e51",
   "metadata": {},
   "source": [
    "<img src= \"propogation.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a9f61",
   "metadata": {},
   "source": [
    "### ```Epoch ```\n",
    "#### is defined as the combination of forward and backword propogation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a916e4d",
   "metadata": {},
   "source": [
    "### Vanishing Gradient Problem and Dead code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f329c9",
   "metadata": {},
   "source": [
    "```ðŸ“Œ Definition:```\n",
    "The vanishing gradient problem occurs during backpropagation in deep neural networks when the gradients (partial derivatives) become very small, almost close to zero. This causes the weights in earlier layers to update very slowly or not at all, which makes the network hard to train.\n",
    "\n",
    "```this arrises due to``` when the architecturre is big like we using 50 nodes. \n",
    "\n",
    "```this occurs in ``` backward propogation it appears to start because in backpropogation due to multiply , when it reach to last hidden layer it becomes almost zero\n",
    "\n",
    "\n",
    "\n",
    "```ðŸ“Œ Definition:```\n",
    "A dead node (or dead neuron) is a neuron that always outputs 0 regardless of the input. It never activates and thus never learns.\n",
    "\n",
    "```this problem occurs due ``` to Relu activation function (max (0,x)) \n",
    "\n",
    "{ if x>0 = x otherwise x<0 = 0 this output 0 will not participate in .}  \n",
    "\n",
    "this problem occurs in hidden layer.\n",
    "\n",
    "for more info [https://chatgpt.com/share/686e0272-30dc-800b-8ef4-d476d2ba1236]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a281a46",
   "metadata": {},
   "source": [
    "### Loss Function (Residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd4a7f",
   "metadata": {},
   "source": [
    "ðŸ”¹ What is a Loss Function?\n",
    "A Loss Function quantifies how well or poorly the model is performing.\n",
    "\n",
    "If the predicted output is very close to the actual output, the loss is low.\n",
    "\n",
    "If it is far, the loss is high.\n",
    "\n",
    "ðŸ“Œ Loss is used during training to adjust the model's weights using optimization algorithms like Gradient Descent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7ba40",
   "metadata": {},
   "source": [
    "Types of Loss Functions:\n",
    "1. linear regression\n",
    "2. Logistic Regression\n",
    "\n",
    "in linear regression loss function is ```mse```,```mae```,```huber```,```log-cosh```\n",
    "\n",
    "in logistic regression loss function is ```cross-entropy```,```hinge```,```logistic```\n",
    "\n",
    "for more info [https://chatgpt.com/share/686e0463-3490-800b-acff-cb09ca72491f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289568a",
   "metadata": {},
   "source": [
    "<img src=\"loss.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19edfc2d",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a6d97",
   "metadata": {},
   "source": [
    "In deep learning, ```optimizers ```are algorithms or methods used to adjust the weights of a neural network to minimize the loss function. Their goal is to help the model learn from data by finding the best set of parameters (weights and biases) that reduce errors in predictions.\n",
    "\n",
    "types of optimizers :\n",
    "1. SGD (Stochastic Gradient Descent)\t\n",
    "2. Momentum\n",
    "3. AdaGrad\t\n",
    "4. RMSProp\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d4b27",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
