{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ab69c6",
   "metadata": {},
   "source": [
    "RNN --> this takes sequential data  --> order important\n",
    "                                    --> semantic meaning understand better than ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf56103",
   "metadata": {},
   "source": [
    "    x1    x2    x3    ...    xt\n",
    "     â†“     â†“     â†“           â†“\n",
    "     h1 â†’  h2 â†’  h3 â†’ ... â†’  ht\n",
    "     â†“     â†“     â†“           â†“\n",
    "     y1    y2    y3          yt\n",
    "\n",
    "\n",
    "\n",
    "     xâ‚œ: input at time t\n",
    "\n",
    "hâ‚œ: hidden state (memory) at time t, depends on xâ‚œ and hâ‚œâ‚‹â‚\n",
    "\n",
    "yâ‚œ: output at time t\n",
    "\n",
    "Hidden state formula: hâ‚œ = f(Wx * xâ‚œ + Wh * hâ‚œâ‚‹â‚ + b)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896c702",
   "metadata": {},
   "source": [
    "types -->\n",
    "1. simple Rnn --> vanilla rnn\n",
    "2. LSTM (long short term memory)\n",
    "3. bidirectional Rnn\n",
    "4. GRU (gated recurrent unit)\n",
    "5. encoder and decoder\n",
    "6. transformer (most important used in chatbots like chatgpt,gemini)\n",
    "7. self "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83426968",
   "metadata": {},
   "source": [
    "GeneratorAI --> LLm, multimodel\n",
    "simple RNN --> LSTM / GRU rnn --> Bidirectional Rnn --> encoder/decoder --> self  --> transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821bcb60",
   "metadata": {},
   "source": [
    "<img src=\"RNNarchi.jpg\" style=\"transform: rotate(270deg);\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19478e",
   "metadata": {},
   "source": [
    "ğŸ§  What is a forward pass?\n",
    "\n",
    "In the forward pass, the model processes input data from start to end, calculating the hidden states and outputs at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380c2c4",
   "metadata": {},
   "source": [
    "### architecture -->\n",
    "\n",
    "Time â†’      t1        t2        t3\n",
    "  \n",
    "           â”Œâ”€â”€â”€â”     â”Œâ”€â”€â”€â”     â”Œâ”€â”€â”€â”\n",
    "\n",
    "Input â†’    â”‚x1 â”‚     â”‚x2 â”‚     â”‚x3 â”‚\n",
    "\n",
    "           â””â†“â”€â”€â”˜     â””â†“â”€â”€â”˜     â””â†“â”€â”€â”˜\n",
    "\n",
    "         â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”\n",
    "\n",
    "Hidden  â†’â”‚ h1  â”‚â†â”€â”€â”‚ h2  â”‚â†â”€â”€â”‚ h3  â”‚\n",
    "\n",
    "         â””â”€â†“â”€â”€â”€â”˜   â””â”€â†“â”€â”€â”€â”˜   â””â”€â†“â”€â”€â”€â”˜\n",
    "\n",
    "Output â†’  y1        y2        y3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31ee90",
   "metadata": {},
   "source": [
    "ğŸ”¢ Formula for forward pass at time t:\n",
    "1. Compute hidden state hâ‚œ:â„ğ‘¡=tanhâ¡(ğ‘ŠxXğ‘¡+ğ‘Šâ„Hğ‘¡âˆ’1+ğ‘)h t =tanh(WxXt +Wh Htâˆ’1 +b)\n",
    "2. Compute output yâ‚œ:ğ‘¦ğ‘¡=ğ‘Šğ‘¦Hğ‘¡+ğ‘ğ‘¦Yt =WyHt +by\n",
    "â€‹\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c36ad7",
   "metadata": {},
   "source": [
    "ğŸ” What is Backpropagation Through Time (BPTT)?\n",
    "BPTT is the backward pass used to train RNNs.\n",
    "It extends the standard backpropagation algorithm by unrolling the RNN through time and computing gradients at each time step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4abd9",
   "metadata": {},
   "source": [
    "Time â†’     t1         t2         t3\n",
    "\n",
    "         â”Œâ”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”\n",
    "x1 â†’     â”‚ Wx â”‚     â”‚ Wx â”‚     â”‚ Wx |\n",
    "\n",
    "         â””â†“â”€â”€â”€â”˜     â””â†“â”€â”€â”€â”˜     â””â†“â”€â”€â”€â”˜\n",
    "\n",
    "         â”Œâ”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”\n",
    "h0 â†’     â”‚ Wh â”‚ â†’   â”‚ Wh â”‚ â†’   â”‚ Wh â”‚\n",
    "\n",
    "         â””â†“â”€â”€â”€â”˜     â””â†“â”€â”€â”€â”˜     â””â†“â”€â”€â”€â”˜\n",
    "\n",
    "         h1         h2         h3\n",
    "         â†“          â†“          â†“\n",
    "\n",
    "         y1         y2         y3\n",
    "\n",
    "         â†“          â†“          â†“\n",
    "       Loss1      Loss2      Loss3\n",
    "       \n",
    "         â†‘          â†‘          â†‘\n",
    "  Backpropagate gradients (BPTT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85b16c",
   "metadata": {},
   "source": [
    "<img src =\"formulabackp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafbdcee",
   "metadata": {},
   "source": [
    "âš ï¸ Common Challenges\n",
    "1. Vanishing Gradients\n",
    "Gradients become very small as they propagate backward in time\n",
    "\n",
    "Long-term dependencies are hard to learn\n",
    "\n",
    "2. Exploding Gradients\n",
    "Gradients grow exponentially, leading to instability\n",
    "\n",
    "Can be fixed with gradient clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e099c9b0",
   "metadata": {},
   "source": [
    "#### for more info visit the blog\n",
    "[https://colah.github.io/]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6d900",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
